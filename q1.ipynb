{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--batch-size N] [--epochs N] [--no-cuda]\n",
      "                             [--no-mps] [--seed S] [--log-interval N]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=c:\\Users\\akobe\\AppData\\Roaming\\jupyter\\runtime\\kernel-v34884347e61239f845f94a96b1c6449840b122f3d.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from q1_train_vae import VAE\n",
    "from q1_vae import log_likelihood_bernoulli, kl_gaussian_gaussian_analytic\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the trained model\n",
    "model = torch.load('model.pt', map_location=device)\n",
    "model.to(device).eval()\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    x_flat = x.view(x.size(0), -1)\n",
    "    recon_loss = -log_likelihood_bernoulli(recon_x, x_flat).sum()\n",
    "    kl = kl_gaussian_gaussian_analytic(\n",
    "        mu, logvar,\n",
    "        torch.zeros_like(mu), torch.zeros_like(logvar)\n",
    "    ).sum()\n",
    "    return recon_loss + kl\n",
    "\n",
    "# Prepare validation data loader\n",
    "batch_size = 128\n",
    "transform = transforms.ToTensor()\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True, transform=transform),\n",
    "    batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "# Compute final validation loss\n",
    "running_val = 0.0\n",
    "with torch.no_grad():\n",
    "    for data, _ in val_loader:\n",
    "        data = data.to(device)\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        running_val += loss_function(recon_batch, data, mu, logvar).item()\n",
    "\n",
    "final_val_loss = running_val / len(val_loader.dataset)\n",
    "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Plot 1: Samples from prior\n",
    "# --------------------------------------------------\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(64, 20).to(device)\n",
    "    samples = model.decode(z).cpu().view(64, 1, 28, 28)\n",
    "grid = make_grid(samples, nrow=8)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(grid.squeeze(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"Samples from VAE Prior\")\n",
    "plt.savefig(\"vae_samples.png\", bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Plot 2: Latent traversals (20 dims Ã— 5 steps)\n",
    "# --------------------------------------------------\n",
    "eps_vals = torch.linspace(-3, 3, 5)\n",
    "fig, axes = plt.subplots(20, 5, figsize=(10, 40))\n",
    "with torch.no_grad():\n",
    "    base_z = torch.randn(1, 20).to(device)\n",
    "    for i in range(20):\n",
    "        for j, eps in enumerate(eps_vals):\n",
    "            z2 = base_z.clone()\n",
    "            z2[0, i] += eps\n",
    "            img = model.decode(z2).cpu().view(28, 28)\n",
    "            axes[i, j].imshow(img, cmap='gray')\n",
    "            axes[i, j].axis('off')\n",
    "plt.suptitle(\"Latent Traversals\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"latent_traversals.png\", bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Plot 3: Interpolation in latent vs data space\n",
    "# --------------------------------------------------\n",
    "alphas = torch.linspace(0, 1, 11)\n",
    "with torch.no_grad():\n",
    "    z0 = torch.randn(1, 20).to(device)\n",
    "    z1 = torch.randn(1, 20).to(device)\n",
    "    latent_imgs = [model.decode(alpha*z0 + (1-alpha)*z1).cpu().view(28, 28) for alpha in alphas]\n",
    "    x0 = model.decode(z0).cpu().view(28, 28)\n",
    "    x1 = model.decode(z1).cpu().view(28, 28)\n",
    "    data_imgs = [(alpha*x0 + (1-alpha)*x1) for alpha in alphas]\n",
    "\n",
    "fig, axes = plt.subplots(2, len(alphas), figsize=(22, 4))\n",
    "for idx in range(len(alphas)):\n",
    "    axes[0, idx].imshow(latent_imgs[idx], cmap='gray')\n",
    "    axes[0, idx].axis('off')\n",
    "    axes[1, idx].imshow(data_imgs[idx], cmap='gray')\n",
    "    axes[1, idx].axis('off')\n",
    "axes[0, 0].set_ylabel(\"Latent Interpolation\")\n",
    "axes[1, 0].set_ylabel(\"Data Interpolation\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"interpolations.png\", bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved plots: vae_samples.png, latent_traversals.png, interpolations.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- model & optimizer ---\n",
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# --- loss function using your q1_vae code ---\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    x_flat = x.view(x.size(0), -1)\n",
    "    recon_loss = -log_likelihood_bernoulli(recon_x, x_flat).sum()\n",
    "    kl = kl_gaussian_gaussian_analytic(mu, logvar,\n",
    "                                       torch.zeros_like(mu),\n",
    "                                       torch.zeros_like(logvar)).sum()\n",
    "    return recon_loss + kl\n",
    "\n",
    "# --- training & validation loops ---\n",
    "num_epochs = 20\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model.train()\n",
    "    running_train = 0.0\n",
    "    for data, _ in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon, mu, logvar = model(data)\n",
    "        loss = loss_function(recon, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        running_train += loss.item()\n",
    "        optimizer.step()\n",
    "    train_losses.append(running_train / len(train_loader.dataset))\n",
    "\n",
    "    model.eval()\n",
    "    running_val = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in val_loader:\n",
    "            data = data.to(device)\n",
    "            recon, mu, logvar = model(data)\n",
    "            running_val += loss_function(recon, data, mu, logvar).item()\n",
    "    val_losses.append(running_val / len(val_loader.dataset))\n",
    "    \n",
    "    print(f\"Epoch {epoch:2d}  Train loss: {train_losses[-1]:.4f}  Val loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "# --- plot losses ---\n",
    "plt.figure()\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label=\"Train\")\n",
    "plt.plot(range(1, num_epochs+1), val_losses, label=\"Val\")\n",
    "plt.xlabel(\"Epoch\"), plt.ylabel(\"Avg Loss\")\n",
    "plt.legend(), plt.title(\"Training vs Validation Loss\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal Validation Loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "# --- samples from prior ---\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(64, 20).to(device)\n",
    "    samples = model.decode(z).cpu().view(64,1,28,28)\n",
    "grid = make_grid(samples, nrow=8)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(grid.squeeze(), cmap='gray')\n",
    "plt.axis('off'), plt.title(\"64 Samples from VAE Prior\")\n",
    "plt.show()\n",
    "\n",
    "# --- latent traversals ---\n",
    "eps_vals = torch.linspace(-3,3,5)\n",
    "fig, axes = plt.subplots(20, 5, figsize=(10,40))\n",
    "with torch.no_grad():\n",
    "    base_z = torch.randn(1,20).to(device)\n",
    "    for i in range(20):\n",
    "        for j, eps in enumerate(eps_vals):\n",
    "            z2 = base_z.clone()\n",
    "            z2[0,i] += eps\n",
    "            img = model.decode(z2).cpu().view(28,28)\n",
    "            axes[i,j].imshow(img, cmap='gray')\n",
    "            axes[i,j].axis('off')\n",
    "plt.suptitle(\"Latent Traversals (rows=latent dim, cols=eps values)\")\n",
    "plt.tight_layout(), plt.show()\n",
    "\n",
    "# --- interpolation latent vs data ---\n",
    "alphas = torch.linspace(0,1,11)\n",
    "with torch.no_grad():\n",
    "    z0, z1 = torch.randn(1,20).to(device), torch.randn(1,20).to(device)\n",
    "    lat_imgs = [model.decode(alpha*z0 + (1-alpha)*z1).cpu().view(28,28) for alpha in alphas]\n",
    "    x0 = model.decode(z0).cpu().view(28,28)\n",
    "    x1 = model.decode(z1).cpu().view(28,28)\n",
    "    data_imgs = [(alpha*x0 + (1-alpha)*x1) for alpha in alphas]\n",
    "\n",
    "fig, axes = plt.subplots(2, len(alphas), figsize=(22,4))\n",
    "for idx in range(len(alphas)):\n",
    "    axes[0,idx].imshow(lat_imgs[idx], cmap='gray'); axes[0,idx].axis('off')\n",
    "    axes[1,idx].imshow(data_imgs[idx], cmap='gray'); axes[1,idx].axis('off')\n",
    "axes[0,0].set_ylabel(\"Latent interp\")\n",
    "axes[1,0].set_ylabel(\"Data interp\")\n",
    "plt.tight_layout(), plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
